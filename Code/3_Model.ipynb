{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1242,"status":"ok","timestamp":1672100965491,"user":{"displayName":"Ya Lin Chen","userId":"17532598296918731232"},"user_tz":480},"id":"3NNo_pZUnjv8"},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/0j/qw0wf1sj6gj4qpttd2789y8c0000gn/T/ipykernel_4150/645041300.py:27: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n","  plt.style.use('seaborn-white')\n","2023-01-01 11:03:50.272135: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["import matplotlib.pyplot as plt\n","\n","import numpy as np\n","import pandas as pd\n","import time \n","import os\n","import sys\n","\n","import pandas as pd\n","import numpy as np\n","\n","import matplotlib.pylab as plt\n","import lightgbm as lgb\n","\n","from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n","from sklearn import preprocessing\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import (\n","    train_test_split,\n","    TimeSeriesSplit,\n","    KFold,\n","    StratifiedKFold,\n","    GroupKFold,\n","    StratifiedGroupKFold,\n",")\n","\n","plt.style.use('seaborn-white')\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers, regularizers\n","import random\n","\n","\n","from sklearn.metrics import accuracy_score, roc_auc_score, make_scorer, precision_score, recall_score\n","from sklearn.model_selection import GridSearchCV"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(87052, 1233)\n","(21535, 1233)\n"]}],"source":["blosum_train_0 = pd.read_csv(os.path.join(sys.path[0],\"Analysis/blosum50_train.csv\"), index_col=False)\n","print(blosum_train_0.shape)\n","\n","blosum_test_0 = pd.read_csv(os.path.join(sys.path[0],\"Analysis/blosum50_test.csv\"), index_col=False)\n","print(blosum_test_0.shape)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(87052, 2065)\n","(21535, 2065)\n"]}],"source":["ifeature_train_0 = pd.read_csv(os.path.join(sys.path[0],\"Analysis/ifeature_train.csv\"), index_col=False)\n","print(ifeature_train_0.shape)\n","\n","ifeature_test_0 = pd.read_csv(os.path.join(sys.path[0],\"Analysis/ifeature_test.csv\"), index_col=False)\n","print(ifeature_test_0.shape)\n","\n","\n","ifeature_train_0 = ifeature_train_0.drop(columns=[\"Unnamed: 0\"])\n","ifeature_test_0 = ifeature_test_0.drop(columns=[\"Unnamed: 0\"])"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def columns_arrange_blosum(df):\n","\n","    df = df.drop(columns=[\"Peptide\",\"Y\", \"MHC\", \"Peptide_L\", \"Peptide_ID\"])\n","\n","    cols = list(df.columns.values) #Make a list of all of the columns in the df\n","    cols.pop(cols.index('y')) #Remove b from list\n","    df = df[cols+['y']]\n","    cols = list(df.columns.values)\n","    cols.pop(cols.index('Pair_ID'))\n","    df = df[['Pair_ID']+cols]\n","    print(df.shape)\n","    \n","    return df"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(87052, 1228)\n","(21535, 1228)\n"]}],"source":["blosum_train = columns_arrange_blosum(blosum_train_0)\n","blosum_test = columns_arrange_blosum(blosum_test_0)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(87052, 2059)\n","(21535, 2059)\n"]}],"source":["ifeature_train = columns_arrange_blosum(ifeature_train_0)\n","ifeature_test = columns_arrange_blosum(ifeature_test_0)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["0    49258\n","1    37794\n","Name: y, dtype: int64"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["blosum_train.y.value_counts()"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["0    12846\n","1     8689\n","Name: y, dtype: int64"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["ifeature_test.y.value_counts()"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["blosum_train_all = blosum_train.drop(columns=[\"Pair_ID\", \"MHC_ID\"])\n","blosum_test_all = blosum_test.drop(columns=[\"Pair_ID\", \"MHC_ID\"])\n","ifeature_train_all = ifeature_train.drop(columns=[\"Pair_ID\", \"MHC_ID\"])\n","ifeature_test_all = ifeature_test.drop(columns=[\"Pair_ID\", \"MHC_ID\"])"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def get_X_y(df, scaler):\n","\n","\n","    X = df.iloc[:,:-1]\n","    X = scaler.transform(X)\n","    # X = tf.convert_to_tensor(X)\n","    y = df.iloc[:,-1]\n","    # y = tf.convert_to_tensor(y)\n","\n","    print(X.shape, y.shape)\n","    \n","    print(\"===end===\")\n","    return X, y"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(87052, 1225) (87052,)\n","===end===\n","(21535, 1225) (21535,)\n","===end===\n"]}],"source":["scaler = MinMaxScaler(feature_range=(0, 1)).fit(blosum_train_all.drop(columns=[\"y\"]))\n","X_blosum_train, y_blosum_train = get_X_y(blosum_train_all, scaler)\n","X_blosum_test, y_blosum_test = get_X_y(blosum_test_all, scaler)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["### blosum feature reshape for RNN\n","# timesteps = 25\n","\n","X_blosum_train_RNN = X_blosum_train.reshape(87052, 25, 49)\n","X_blosum_test_RNN = X_blosum_test.reshape(21535, 25, 49)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(87052, 2056) (87052,)\n","===end===\n","(21535, 2056) (21535,)\n","===end===\n"]}],"source":["scaler = MinMaxScaler(feature_range=(0, 1)).fit(ifeature_train_all.drop(columns=[\"y\"]))\n","X_ifeature_train, y_ifeature_train = get_X_y(ifeature_train_all, scaler)\n","X_ifeature_test, y_ifeature_test = get_X_y(ifeature_test_all, scaler)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["del blosum_train_0, blosum_test_0, ifeature_train_0, ifeature_test_0"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["def test_evaluation(model, X_test, y_test):\n","    pred_label_1 = model.predict(X_test, batch_size=128, verbose=2)\n","    pred_label_number_1 = np.argmax(pred_label_1, axis=1)\n","    test_labels = y_test\n","    report = classification_report(test_labels, pred_label_number_1, digits = 3)\n","    print(report)\n","    print(\"AUROC:\", roc_auc_score(test_labels, pred_label_number_1))\n","\n","    return pred_label_1, pred_label_number_1, report"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 1. combined (RNN+DNN)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["def individual_blosum(X_blosum, X_blosum_t, X_ifeature, X_ifeature_t, Y, Y_t, neuron1, neuron2, epoch1, epoch2):\n","\n","    # Model1\n","    inputs = keras.Input(shape=X_blosum.shape[1:])\n","    x = layers.SimpleRNN(neuron1, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01), return_sequences=True)(inputs)\n","    x = layers.SimpleRNN(245, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(inputs)\n","    outputs = layers.Dense(2, name = 'my_layer')(x)\n","\n","    model = keras.Model(inputs=inputs, outputs = outputs)\n","\n","    model.compile(\n","    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n","    # if use CategoricalCrossentropy, then the output should be one-hot encoded\n","    optimizer = keras.optimizers.Adamax(learning_rate=0.001),\n","    metrics=[\"accuracy\"] # the metrics keras will keep tracking during the training\n","    )\n","\n","    model.fit(X_blosum, Y, batch_size=128, epochs=epoch1, verbose=2)\n","\n","    \n","    model = keras.Model(inputs=inputs, outputs=[layer.output for layer in model.layers])\n","    features = model.predict(X_blosum, batch_size=128)\n","    features_test = model.predict(X_blosum_t, batch_size=128)\n","\n","    base_output = features[1]\n","    print(\"train latent output: \", base_output.shape)\n","    base_output_t = features_test[1]\n","    print(\"test latent output: \", base_output_t.shape)\n","    \n","    \n","    # Model2\n","    X_concat = np.concatenate((base_output, X_ifeature), axis=1)\n","    X_concat_t = np.concatenate((base_output_t, X_ifeature_t), axis=1)\n","\n","    inputs = keras.Input(shape=X_concat.shape[1])\n","    x = layers.Dense(neuron2, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(inputs)\n","    x = layers.Dropout(0.5)(x)\n","    # x = layers.Dense(neuron3, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(inputs)\n","    outputs = layers.Dense(2)(x)\n","\n","\n","    model = keras.Model(inputs=inputs, outputs=outputs)\n","\n","    model.compile(\n","    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n","    # if use CategoricalCrossentropy, then the output should be one-hot encoded\n","    optimizer = keras.optimizers.Adamax(learning_rate=0.001),\n","    metrics=[\"accuracy\"] # the metrics keras will keep tracking during the training\n","    )\n","\n","    model.fit(X_concat, Y, batch_size=128, epochs = epoch2, verbose=2)\n","\n","    pred_label_1 = model.predict(X_concat_t, batch_size=128, verbose=2)\n","    pred_label_number_1 = np.argmax(pred_label_1, axis=1)\n","    test_labels = Y_t\n","\n","    report = classification_report(test_labels, pred_label_number_1, digits = 3)\n","    print(report)\n","    print(\"AUROC:\", roc_auc_score(test_labels, pred_label_number_1))\n","    print(\"test latent output: \", base_output_t.shape)\n","\n","\n","    return model, pred_label_1, pred_label_number_1, report"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","681/681 - 13s - loss: 0.8176 - accuracy: 0.7159 - 13s/epoch - 20ms/step\n","Epoch 2/20\n","681/681 - 12s - loss: 0.5958 - accuracy: 0.7467 - 12s/epoch - 18ms/step\n","Epoch 3/20\n","681/681 - 14s - loss: 0.5491 - accuracy: 0.7558 - 14s/epoch - 20ms/step\n","Epoch 4/20\n","681/681 - 14s - loss: 0.5268 - accuracy: 0.7611 - 14s/epoch - 20ms/step\n","Epoch 5/20\n","681/681 - 16s - loss: 0.5109 - accuracy: 0.7658 - 16s/epoch - 23ms/step\n","Epoch 6/20\n","681/681 - 15s - loss: 0.5023 - accuracy: 0.7698 - 15s/epoch - 22ms/step\n","Epoch 7/20\n","681/681 - 14s - loss: 0.4964 - accuracy: 0.7734 - 14s/epoch - 20ms/step\n","Epoch 8/20\n","681/681 - 14s - loss: 0.4902 - accuracy: 0.7764 - 14s/epoch - 20ms/step\n","Epoch 9/20\n","681/681 - 14s - loss: 0.4862 - accuracy: 0.7788 - 14s/epoch - 20ms/step\n","Epoch 10/20\n","681/681 - 14s - loss: 0.4824 - accuracy: 0.7819 - 14s/epoch - 20ms/step\n","Epoch 11/20\n","681/681 - 14s - loss: 0.4772 - accuracy: 0.7855 - 14s/epoch - 20ms/step\n","Epoch 12/20\n","681/681 - 14s - loss: 0.4709 - accuracy: 0.7887 - 14s/epoch - 20ms/step\n","Epoch 13/20\n","681/681 - 14s - loss: 0.4674 - accuracy: 0.7909 - 14s/epoch - 20ms/step\n","Epoch 14/20\n","681/681 - 14s - loss: 0.4647 - accuracy: 0.7949 - 14s/epoch - 20ms/step\n","Epoch 15/20\n","681/681 - 14s - loss: 0.4625 - accuracy: 0.7942 - 14s/epoch - 20ms/step\n","Epoch 16/20\n","681/681 - 14s - loss: 0.4598 - accuracy: 0.7977 - 14s/epoch - 21ms/step\n","Epoch 17/20\n","681/681 - 15s - loss: 0.4545 - accuracy: 0.8007 - 15s/epoch - 21ms/step\n","Epoch 18/20\n","681/681 - 15s - loss: 0.4489 - accuracy: 0.8034 - 15s/epoch - 22ms/step\n","Epoch 19/20\n","681/681 - 15s - loss: 0.4484 - accuracy: 0.8041 - 15s/epoch - 22ms/step\n","Epoch 20/20\n","681/681 - 14s - loss: 0.4433 - accuracy: 0.8088 - 14s/epoch - 21ms/step\n","681/681 [==============================] - 7s 10ms/step\n","169/169 [==============================] - 2s 12ms/step\n","train latent output:  (87052, 245)\n","test latent output:  (21535, 245)\n","Epoch 1/20\n","681/681 - 5s - loss: 1.2767 - accuracy: 0.7472 - 5s/epoch - 7ms/step\n","Epoch 2/20\n","681/681 - 4s - loss: 0.6014 - accuracy: 0.7816 - 4s/epoch - 6ms/step\n","Epoch 3/20\n","681/681 - 4s - loss: 0.5240 - accuracy: 0.7847 - 4s/epoch - 5ms/step\n","Epoch 4/20\n","681/681 - 4s - loss: 0.5041 - accuracy: 0.7891 - 4s/epoch - 5ms/step\n","Epoch 5/20\n","681/681 - 4s - loss: 0.4957 - accuracy: 0.7915 - 4s/epoch - 5ms/step\n","Epoch 6/20\n","681/681 - 5s - loss: 0.4929 - accuracy: 0.7906 - 5s/epoch - 8ms/step\n","Epoch 7/20\n","681/681 - 4s - loss: 0.4856 - accuracy: 0.7958 - 4s/epoch - 6ms/step\n","Epoch 8/20\n","681/681 - 4s - loss: 0.4870 - accuracy: 0.7930 - 4s/epoch - 6ms/step\n","Epoch 9/20\n","681/681 - 4s - loss: 0.4840 - accuracy: 0.7951 - 4s/epoch - 6ms/step\n","Epoch 10/20\n","681/681 - 4s - loss: 0.4821 - accuracy: 0.7968 - 4s/epoch - 6ms/step\n","Epoch 11/20\n","681/681 - 4s - loss: 0.4846 - accuracy: 0.7934 - 4s/epoch - 5ms/step\n","Epoch 12/20\n","681/681 - 4s - loss: 0.4820 - accuracy: 0.7942 - 4s/epoch - 5ms/step\n","Epoch 13/20\n","681/681 - 4s - loss: 0.4836 - accuracy: 0.7921 - 4s/epoch - 6ms/step\n","Epoch 14/20\n","681/681 - 4s - loss: 0.4789 - accuracy: 0.7955 - 4s/epoch - 5ms/step\n","Epoch 15/20\n","681/681 - 4s - loss: 0.4871 - accuracy: 0.7888 - 4s/epoch - 6ms/step\n","Epoch 16/20\n","681/681 - 4s - loss: 0.4847 - accuracy: 0.7898 - 4s/epoch - 6ms/step\n","Epoch 17/20\n","681/681 - 4s - loss: 0.4864 - accuracy: 0.7891 - 4s/epoch - 5ms/step\n","Epoch 18/20\n","681/681 - 4s - loss: 0.4836 - accuracy: 0.7919 - 4s/epoch - 6ms/step\n","Epoch 19/20\n","681/681 - 4s - loss: 0.4874 - accuracy: 0.7880 - 4s/epoch - 6ms/step\n","Epoch 20/20\n","681/681 - 4s - loss: 0.4866 - accuracy: 0.7904 - 4s/epoch - 6ms/step\n","169/169 - 1s - 571ms/epoch - 3ms/step\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.73      0.78     12846\n","           1       0.66      0.78      0.72      8689\n","\n","    accuracy                           0.75     21535\n","   macro avg       0.75      0.76      0.75     21535\n","weighted avg       0.76      0.75      0.75     21535\n","\n","AUROC: 0.7553409461305001\n","test latent output:  (21535, 245)\n"]}],"source":["model_combine, pred_label_combined, pred_label_number_combined, report_combined = individual_blosum(X_blosum_train_RNN, X_blosum_test_RNN, X_ifeature_train, X_ifeature_test, y_ifeature_train , y_ifeature_test, 60, 257, 20, 20)"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0      0.832     0.728     0.776     12846\n","           1      0.661     0.783     0.716      8689\n","\n","    accuracy                          0.750     21535\n","   macro avg      0.746     0.755     0.746     21535\n","weighted avg      0.763     0.750     0.752     21535\n","\n","AUROC: 0.7553409461305001\n"]}],"source":["report_combined = classification_report(y_ifeature_test, pred_label_number_combined, digits = 3)\n","print(report_combined)\n","print(\"AUROC:\", roc_auc_score(y_ifeature_test, pred_label_number_combined))"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["state=\"train1_combined_model\"\n","\n","\n","lines = report_combined\n","auroc = str(0.7553409461305001)\n","\n","with open('Result/class_report_%s.txt'%(state), 'w') as f:\n","    for line in lines:\n","        f.write(line)\n","    f.write(auroc)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# Format 2\n","def individual_blosum(X, Y, neuron, epoch):\n","\n","  ### build layers\n","  model = keras.Sequential(\n","      [\n","          keras.Input(shape=X.shape[1:]),\n","          layers.SimpleRNN(neuron, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01), return_sequences=True),\n","          layers.SimpleRNN(245, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01)),\n","          # layers.Dropout(0.5),\n","        #   layers.SimpleRNN(neuron, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01)),\n","          # layers.Dense(neuron, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01)),\n","          layers.Dense(2),\n","      ]\n","  )\n","\n","  print(model.summary())\n","\n","\n","  \n","  ### compile the model configuration\n","  model.compile(\n","      loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n","      # if use CategoricalCrossentropy, then the output should be one-hot encoded\n","      optimizer = keras.optimizers.Adamax(learning_rate=0.001),\n","      metrics=[\"accuracy\"] # the metrics keras will keep tracking during the training (tf.keras.metrics.AUC())\n","  )\n","\n","  ### fit the data\n","  # callback = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True), validation_data=(X_test, Y_test),callbacks = [callback]\n","  history = model.fit(X, Y, batch_size=128, epochs=epoch, verbose=2)\n","\n","  return model"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-01-01 10:40:21.916207: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]},{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," simple_rnn (SimpleRNN)      (None, 25, 60)            6600      \n","                                                                 \n"," simple_rnn_1 (SimpleRNN)    (None, 245)               74970     \n","                                                                 \n"," dense (Dense)               (None, 2)                 492       \n","                                                                 \n","=================================================================\n","Total params: 82,062\n","Trainable params: 82,062\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/20\n","681/681 - 17s - loss: 1.0349 - accuracy: 0.7057 - 17s/epoch - 25ms/step\n","Epoch 2/20\n","681/681 - 15s - loss: 0.6837 - accuracy: 0.7346 - 15s/epoch - 23ms/step\n","Epoch 3/20\n","681/681 - 15s - loss: 0.6095 - accuracy: 0.7412 - 15s/epoch - 23ms/step\n","Epoch 4/20\n","681/681 - 16s - loss: 0.5737 - accuracy: 0.7484 - 16s/epoch - 23ms/step\n","Epoch 5/20\n","681/681 - 16s - loss: 0.5551 - accuracy: 0.7521 - 16s/epoch - 23ms/step\n","Epoch 6/20\n","681/681 - 16s - loss: 0.5427 - accuracy: 0.7537 - 16s/epoch - 24ms/step\n","Epoch 7/20\n","681/681 - 16s - loss: 0.5321 - accuracy: 0.7583 - 16s/epoch - 24ms/step\n","Epoch 8/20\n","681/681 - 17s - loss: 0.5241 - accuracy: 0.7616 - 17s/epoch - 24ms/step\n","Epoch 9/20\n","681/681 - 17s - loss: 0.5187 - accuracy: 0.7634 - 17s/epoch - 25ms/step\n","Epoch 10/20\n","681/681 - 17s - loss: 0.5157 - accuracy: 0.7644 - 17s/epoch - 25ms/step\n","Epoch 11/20\n","681/681 - 17s - loss: 0.5105 - accuracy: 0.7681 - 17s/epoch - 25ms/step\n","Epoch 12/20\n","681/681 - 17s - loss: 0.5073 - accuracy: 0.7681 - 17s/epoch - 25ms/step\n","Epoch 13/20\n","681/681 - 18s - loss: 0.5036 - accuracy: 0.7710 - 18s/epoch - 27ms/step\n","Epoch 14/20\n","681/681 - 18s - loss: 0.4996 - accuracy: 0.7752 - 18s/epoch - 26ms/step\n","Epoch 15/20\n","681/681 - 17s - loss: 0.4982 - accuracy: 0.7738 - 17s/epoch - 25ms/step\n","Epoch 16/20\n","681/681 - 22s - loss: 0.4934 - accuracy: 0.7776 - 22s/epoch - 32ms/step\n","Epoch 17/20\n","681/681 - 21s - loss: 0.4918 - accuracy: 0.7785 - 21s/epoch - 31ms/step\n","Epoch 18/20\n","681/681 - 17s - loss: 0.4866 - accuracy: 0.7815 - 17s/epoch - 26ms/step\n","Epoch 19/20\n","681/681 - 18s - loss: 0.4866 - accuracy: 0.7806 - 18s/epoch - 26ms/step\n","Epoch 20/20\n","681/681 - 17s - loss: 0.4860 - accuracy: 0.7820 - 17s/epoch - 25ms/step\n"]}],"source":["model_blosum = individual_blosum(X_blosum_train_RNN, y_blosum_train, 60, 20)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/plain":["<keras.engine.sequential.Sequential at 0x156e549a0>"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["model_blosum"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["169/169 - 2s - 2s/epoch - 10ms/step\n","              precision    recall  f1-score   support\n","\n","           0      0.787     0.801     0.794     12846\n","           1      0.697     0.679     0.688      8689\n","\n","    accuracy                          0.752     21535\n","   macro avg      0.742     0.740     0.741     21535\n","weighted avg      0.751     0.752     0.751     21535\n","\n","AUROC: 0.7398678130603946\n"]}],"source":["blosum_all_label, blosum_all_label_number, blosum_report = test_evaluation(model_blosum, X_blosum_test_RNN, y_blosum_test)"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["state=\"train1_blosum\"\n","\n","\n","lines = blosum_report\n","auroc = str(0.7398678130603946)\n","\n","with open('Result/class_report_%s.txt'%(state), 'w') as f:\n","    for line in lines:\n","        f.write(line)\n","    f.write(auroc)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### iFeature"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["# Format 2\n","def individual_ifeature(X, Y, neuron, epoch):\n","\n","  ### build layers\n","  model = keras.Sequential(\n","      [\n","          keras.Input(shape=X.shape[1]),\n","          layers.Dense(neuron, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01)),  \n","          layers.Dropout(0.5),\n","        #   layers.Dense(neuron, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01)),\n","        #   layers.Dropout(0.5),\n","        #   layers.Dense(neuron, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01)),\n","          layers.Dense(2, activation=\"softmax\"),\n","      ]\n","  )\n","\n","  print(model.summary())\n","\n","\n","  \n","  ### compile the model configuration\n","  model.compile(\n","      loss = keras.losses.SparseCategoricalCrossentropy(), \n","      # if use CategoricalCrossentropy, then the output should be one-hot encoded\n","      optimizer = keras.optimizers.Adamax(learning_rate=0.001),\n","      metrics=[\"accuracy\"] # the metrics keras will keep tracking during the training (tf.keras.metrics.AUC())\n","  )\n","\n","  ### fit the data\n","  # callback = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True), validation_data=(X_test, Y_test),callbacks = [callback]\n","  history = model.fit(X, Y, batch_size=128, epochs=epoch, verbose=2)\n","\n","  return model"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_4 (Dense)             (None, 257)               528649    \n","                                                                 \n"," dropout_2 (Dropout)         (None, 257)               0         \n","                                                                 \n"," dense_5 (Dense)             (None, 2)                 516       \n","                                                                 \n","=================================================================\n","Total params: 529,165\n","Trainable params: 529,165\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/10\n","681/681 - 3s - loss: 1.3697 - accuracy: 0.6906 - 3s/epoch - 5ms/step\n","Epoch 2/10\n","681/681 - 3s - loss: 0.6791 - accuracy: 0.7107 - 3s/epoch - 4ms/step\n","Epoch 3/10\n","681/681 - 3s - loss: 0.6014 - accuracy: 0.7144 - 3s/epoch - 4ms/step\n","Epoch 4/10\n","681/681 - 3s - loss: 0.5865 - accuracy: 0.7178 - 3s/epoch - 4ms/step\n","Epoch 5/10\n","681/681 - 3s - loss: 0.5835 - accuracy: 0.7174 - 3s/epoch - 4ms/step\n","Epoch 6/10\n","681/681 - 3s - loss: 0.5792 - accuracy: 0.7198 - 3s/epoch - 4ms/step\n","Epoch 7/10\n","681/681 - 3s - loss: 0.5756 - accuracy: 0.7204 - 3s/epoch - 4ms/step\n","Epoch 8/10\n","681/681 - 3s - loss: 0.5754 - accuracy: 0.7204 - 3s/epoch - 4ms/step\n","Epoch 9/10\n","681/681 - 3s - loss: 0.5748 - accuracy: 0.7198 - 3s/epoch - 4ms/step\n","Epoch 10/10\n","681/681 - 3s - loss: 0.5767 - accuracy: 0.7195 - 3s/epoch - 4ms/step\n"]}],"source":["model_ifeature = individual_ifeature(X_ifeature_train, y_ifeature_train, 257, 10)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["169/169 - 0s - 432ms/epoch - 3ms/step\n","              precision    recall  f1-score   support\n","\n","           0      0.781     0.721     0.750     12846\n","           1      0.629     0.700     0.663      8689\n","\n","    accuracy                          0.713     21535\n","   macro avg      0.705     0.711     0.706     21535\n","weighted avg      0.720     0.713     0.715     21535\n","\n","AUROC: 0.7107142362474942\n"]}],"source":["ifeature_all_label, ifeature_all_label_number, ifeature_report = test_evaluation(model_ifeature, X_ifeature_test, y_ifeature_test)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["state=\"train1_ifeature\"\n","\n","\n","lines = ifeature_report\n","auroc = str(0.7107142362474942)\n","\n","with open('Result/class_report_%s.txt'%(state), 'w') as f:\n","    for line in lines:\n","        f.write(line)\n","    f.write(auroc)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1Btaz4hobaJNvE5C0iisrl-qb77BKxgqW","timestamp":1671037895180}]},"gpuClass":"standard","kernelspec":{"display_name":"my_tensorflow","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"vscode":{"interpreter":{"hash":"a610de6248b56eaee9e1364ae023def340444b098e1c9bedd32e10334a238d13"}}},"nbformat":4,"nbformat_minor":0}
